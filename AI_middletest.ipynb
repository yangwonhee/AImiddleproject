{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c362ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from random import random, shuffle, choices, randrange\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "import sentencepiece as spm\n",
    "import wget\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096c22a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 15 19:54:13 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:17:00.0  On |                  N/A |\r\n",
      "| 81%   81C    P2   307W / 420W |  23792MiB / 24260MiB |     81%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1008      G   /usr/lib/xorg/Xorg                200MiB |\r\n",
      "|    0   N/A  N/A     42280      G   cinnamon                           18MiB |\r\n",
      "|    0   N/A  N/A     42553      G   ...AAAAAAAAA= --shared-files       21MiB |\r\n",
      "|    0   N/A  N/A     43198      C   ...mlbi/anaconda3/bin/python    23547MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecc3c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\r\n",
      "Built on Tue_Mar__8_18:18:20_PST_2022\r\n",
      "Cuda compilation tools, release 11.6, V11.6.124\r\n",
      "Build cuda_11.6.r11.6/compiler.31057947_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44cddc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0511f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "data_dir = '/mnt/HDD1/Work_wonhee/ai_lec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d449867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file = f\"{data_dir}/kowiki_t5.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d055bee",
   "metadata": {},
   "source": [
    "## 1.kowiki textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71078a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/HDD1/Work_wonhee/school/AI_lecture'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecfc88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f3e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"./web-crawler/kowiki/kowiki_20230512.csv\"\n",
    "out_file = \"kowiki.txt\"\n",
    "SEPARATOR = u\"\\u241D\"\n",
    "df = pd.read_csv(in_file, sep=SEPARATOR, engine=\"python\")\n",
    "with open(out_file, \"w\") as f:\n",
    "  for index, row in df.iterrows():\n",
    "    f.write(row[\"text\"]) # title 과 text를 중복 되므로 text만 저장 함\n",
    "    f.write(\"\\n\\n\\n\\n\") # 구분자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084db1d6",
   "metadata": {},
   "source": [
    "## 2. Config\n",
    "모델에 설정 값을 전달하기 위한 config를 만듦."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce123117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
    "class Config(dict): \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5fb0378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_vocab': 8033, 'n_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
     ]
    }
   ],
   "source": [
    "config = Config({\n",
    "    \"n_vocab\": len(vocab),\n",
    "    \"n_seq\": 256,\n",
    "    \"n_layer\": 6,\n",
    "    \"d_hidn\": 256,\n",
    "    \"i_pad\": 0,\n",
    "    \"d_ff\": 1024,\n",
    "    \"n_head\": 4,\n",
    "    \"d_head\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"layer_norm_epsilon\": 1e-12\n",
    "})\n",
    "print(config)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105db4d6",
   "metadata": {},
   "source": [
    "## 3. T5\n",
    "T5 class, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff385577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" attention pad mask \"\"\"\n",
    "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # \n",
    "    return pad_attn_mask\n",
    "\n",
    "\n",
    "\"\"\" attention decoder mask \"\"\"\n",
    "def get_attn_decoder_mask(seq):\n",
    "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
    "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "\"\"\" scale dot product attention \"\"\"\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
    "        self.num_buckets = 32\n",
    "        self.relative_attention_bias = torch.nn.Embedding(self.num_buckets, self.config.n_head)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask, bidirectional=True):\n",
    "        qlen, klen = Q.size(-2), K.size(-2)\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
    "        # (1, n_head, n_q_seq, n_k_seq)\n",
    "        position_bias = self.compute_bias(qlen, klen, bidirectional=bidirectional)\n",
    "        scores += position_bias\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
    "        attn_prob = self.dropout(attn_prob)\n",
    "        # (bs, n_head, n_q_seq, d_v)\n",
    "        context = torch.matmul(attn_prob, V)\n",
    "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
    "        return context, attn_prob\n",
    "    \n",
    "    def compute_bias(self, qlen, klen, bidirectional=True):\n",
    "        context_position = torch.arange(qlen, dtype=torch.long)[:, None]\n",
    "        memory_position = torch.arange(klen, dtype=torch.long)[None, :]\n",
    "        # (qlen, klen)\n",
    "        relative_position = memory_position - context_position\n",
    "        # (qlen, klen)\n",
    "        rp_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (qlen, klen)\n",
    "            num_buckets=self.num_buckets,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        # (qlen, klen)\n",
    "        rp_bucket = rp_bucket.to(self.relative_attention_bias.weight.device)\n",
    "        # (qlen, klen, n_head)\n",
    "        values = self.relative_attention_bias(rp_bucket)\n",
    "        # (1, n_head, qlen, klen)\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(0)\n",
    "        return values\n",
    "\n",
    "    def _relative_position_bucket(self, relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n",
    "        ret = 0\n",
    "        n = -relative_position\n",
    "        if bidirectional:\n",
    "            num_buckets //= 2\n",
    "            ret += (n < 0).to(torch.long) * num_buckets  # mtf.to_int32(mtf.less(n, 0)) * num_buckets\n",
    "            n = torch.abs(n)\n",
    "        else:\n",
    "            n = torch.max(n, torch.zeros_like(n))\n",
    "\n",
    "        # half of the buckets are for exact increments in positions\n",
    "        max_exact = num_buckets // 2\n",
    "        is_small = n < max_exact\n",
    "\n",
    "        # The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
    "        val_if_large = max_exact + (\n",
    "                torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)\n",
    "        ).to(torch.long)\n",
    "        val_if_large = torch.min(val_if_large, torch.full_like(val_if_large, num_buckets - 1))\n",
    "\n",
    "        ret += torch.where(is_small, n, val_if_large)\n",
    "        return ret\n",
    "\n",
    "\n",
    "\"\"\" multi head attention \"\"\"\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
    "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, Q, K, V, attn_mask, bidirectional=False):\n",
    "        batch_size = Q.size(0)\n",
    "        # (bs, n_head, n_q_seq, d_head)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        # (bs, n_head, n_k_seq, d_head)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        # (bs, n_head, n_v_seq, d_head)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "\n",
    "        # (bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
    "\n",
    "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask, bidirectional=bidirectional)\n",
    "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
    "        # (bs, n_head, n_q_seq, e_embd)\n",
    "        output = self.linear(context)\n",
    "        output = self.dropout(output)\n",
    "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        return output, attn_prob\n",
    "\n",
    "\n",
    "\"\"\" feed forward \"\"\"\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
    "        self.active = F.gelu\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # (bs, d_ff, n_seq)\n",
    "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        output = self.conv2(output).transpose(1, 2)\n",
    "        output = self.dropout(output)\n",
    "        # (bs, n_seq, d_hidn)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7616131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" encoder layer \"\"\"\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "    \n",
    "    def forward(self, inputs, attn_mask):\n",
    "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
    "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
    "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
    "        # (bs, n_enc_seq, d_hidn)\n",
    "        ffn_outputs = self.pos_ffn(att_outputs)\n",
    "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
    "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
    "        return ffn_outputs, attn_prob\n",
    "\n",
    "\n",
    "\"\"\" encoder \"\"\"\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "    \n",
    "    def forward(self, enc_embd, enc_self_mask):\n",
    "        # (bs, n_enc_seq, d_hidn)\n",
    "        enc_outputs = enc_embd\n",
    "\n",
    "        attn_probs = []\n",
    "        for layer in self.layers:\n",
    "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
    "            enc_outputs, attn_prob = layer(enc_outputs, enc_self_mask)\n",
    "            attn_probs.append(attn_prob)\n",
    "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        return enc_outputs, attn_probs\n",
    "\n",
    "\n",
    "\"\"\" decoder layer \"\"\"\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        self.dec_enc_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
    "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
    "    \n",
    "    def forward(self, dec_inputs, enc_outputs, self_mask, ende_mask):\n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
    "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_mask, bidirectional=False)\n",
    "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, ende_mask)\n",
    "        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n",
    "        # (bs, n_dec_seq, d_hidn)\n",
    "        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n",
    "        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n",
    "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob\n",
    "\n",
    "\n",
    "\"\"\" decoder \"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "    \n",
    "    def forward(self, dec_embd, enc_outputs, self_mask, ende_mask):\n",
    "        # (bs, n_dec_seq, d_hidn)\n",
    "        dec_outputs = dec_embd\n",
    "\n",
    "        self_attn_probs, dec_enc_attn_probs = [], []\n",
    "        for layer in self.layers:\n",
    "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n",
    "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, self_mask, ende_mask)\n",
    "            self_attn_probs.append(self_attn_prob)\n",
    "            dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
    "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n",
    "        return dec_outputs, self_attn_probs, dec_enc_attn_probs\n",
    "\n",
    "\n",
    "\"\"\" t5 \"\"\"\n",
    "class T5(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.embedding = nn.Embedding(self.config.n_vocab, self.config.d_hidn)\n",
    "        self.encoder = Encoder(self.config)\n",
    "        self.decoder = Decoder(self.config)\n",
    "\n",
    "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_vocab, bias=False)\n",
    "        self.projection_lm.weight = self.embedding.weight\n",
    "    \n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        enc_embd = self.embedding(enc_inputs)\n",
    "        dec_embd = self.embedding(dec_inputs)\n",
    "\n",
    "        enc_self_mask = get_attn_pad_mask(enc_inputs, enc_inputs, self.config.i_pad)\n",
    "        dec_self_mask = self.get_attn_dec_mask(dec_inputs)\n",
    "        dec_ende_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n",
    "\n",
    "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
    "        enc_outputs, enc_self_attn_probs = self.encoder(enc_embd, enc_self_mask)\n",
    "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
    "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_embd, enc_outputs, dec_self_mask, dec_ende_mask)\n",
    "        # (bs, n_dec_seq, n_vocab)\n",
    "        dec_outputs = self.projection_lm(dec_outputs)\n",
    "        # (bs, n_dec_seq, n_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
    "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs\n",
    "    \n",
    "    def get_attn_dec_mask(self, dec_inputs):\n",
    "         # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_ahead_mask = get_attn_decoder_mask(dec_inputs)\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        dec_self_mask = torch.gt((dec_pad_mask + dec_ahead_mask), 0)\n",
    "        # (bs, n_dec_seq, n_dec_seq)\n",
    "        return dec_self_mask\n",
    "\n",
    "    def save(self, epoch, loss, path):\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss,\n",
    "            \"state_dict\": self.state_dict()\n",
    "        }, path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        save = torch.load(path)\n",
    "        self.load_state_dict(save[\"state_dict\"])\n",
    "        return save[\"epoch\"], save[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bac175",
   "metadata": {},
   "source": [
    "## 4. Pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0db8568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" T5 pretrain \"\"\"\n",
    "class T5Pretrain(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.t5 = T5(self.config)\n",
    "    \n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        # (bs, n_dec_seq, n_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
    "        logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.t5(enc_inputs, dec_inputs)\n",
    "        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed768a8",
   "metadata": {},
   "source": [
    "## 5. Pretrain Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cbdb567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 mask 길이: 2.9434954007884366\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SPAN_LEN = 8\n",
    "SPAN_VALUE = np.array([i+1 for i in range(SPAN_LEN)])\n",
    "SPAN_RATIO = np.array([1/i for i in SPAN_VALUE])\n",
    "SPAN_RATIO = SPAN_RATIO / np.sum(SPAN_RATIO)\n",
    "\n",
    "print(f\"평균 mask 길이: {np.sum(SPAN_VALUE * SPAN_RATIO)}\")\n",
    "\n",
    "# graph\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.plot(SPAN_RATIO, label=\"ration\")\n",
    "plt.legend()\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Ratioo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7affae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SPAN 길이 \"\"\"\n",
    "def get_span_length():\n",
    "    return choices(SPAN_VALUE, SPAN_RATIO)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87ff40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    cand_idx = {}\n",
    "    index = 0\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        masks.append(None)\n",
    "        if token == \"[BOS]\" or token == \"[EOS]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "            cand_idx[index].append(i)\n",
    "        else:\n",
    "            index += 1\n",
    "            cand_idx[index] = [i]\n",
    "    assert len(masks) == len(tokens)\n",
    "    keys = list(cand_idx.keys())\n",
    "    shuffle(keys)\n",
    "\n",
    "    mask_lms = []\n",
    "    covered_idx = set()\n",
    "    for index in keys:\n",
    "        if len(mask_lms) >= mask_cnt:\n",
    "            break\n",
    "        span_len = get_span_length()\n",
    "        # 남은 토큰개수고 마스크 토큰 캐수보다 작은 경우\n",
    "        if len(cand_idx) <= index + span_len:\n",
    "            continue\n",
    "        index_set = []\n",
    "        # mask할 토큰의 index 저장\n",
    "        for i in range(span_len):\n",
    "            index_set.extend(cand_idx[index + i])\n",
    "        # 마스크 개수 초과 방지\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:\n",
    "            continue\n",
    "        # 이미 마스크 된 경우가 있는지 확인\n",
    "        is_idx_covered = False\n",
    "        for index in index_set:\n",
    "            if index in covered_idx:\n",
    "                is_idx_covered = True\n",
    "                break\n",
    "        if is_idx_covered:\n",
    "            continue\n",
    "\n",
    "        for index in index_set:\n",
    "            covered_idx.add(index)\n",
    "            masked_token = None\n",
    "            mask_lms.append({\"index\": index, \"span_idx1\": index_set[0] - 1, \"span_idx2\": index_set[-1] + 1, \"label\": tokens[index]})\n",
    "            masks[index] = tokens[index]\n",
    "            tokens[index] = masked_token\n",
    "        # span boundary\n",
    "        covered_idx.add(index_set[0] - 1)\n",
    "        covered_idx.add(index_set[-1] + 1)\n",
    "\n",
    "    enc_input, dec_input = [], []\n",
    "    ascii_index = 65\n",
    "    is_mask = False\n",
    "    for i, token in enumerate(tokens):\n",
    "        if is_mask:\n",
    "            if token is None:\n",
    "                dec_input.append(masks[i])\n",
    "            else:\n",
    "                enc_input.append(token)\n",
    "                is_mask = False\n",
    "        else:\n",
    "            if token is None:\n",
    "                enc_input.append(f\"<{chr(ascii_index)}>\")\n",
    "                dec_input.append(f\"<{chr(ascii_index)}>\")\n",
    "                dec_input.append(masks[i])\n",
    "                ascii_index += 1\n",
    "                is_mask = True\n",
    "            else:\n",
    "                enc_input.append(token)\n",
    "    if 0 < len(dec_input):\n",
    "        dec_input.append(\"\")\n",
    "    return enc_input, dec_input\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9178395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(docs, doc_idx, doc, n_seq, mask_prob):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for [BOS], [EOS]\n",
    "    max_seq = n_seq - 2\n",
    "    tgt_seq = max_seq\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line\n",
    "        current_length += len(doc[i])\n",
    "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
    "            if 0 < len(current_chunk):\n",
    "                tokens = []\n",
    "                for chunk in current_chunk: tokens.extend(chunk)\n",
    "                tokens = tokens[:tgt_seq]\n",
    "                enc_input, dec_input = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob))\n",
    "\n",
    "                instance = {\n",
    "                    \"enc_input\": enc_input,\n",
    "                    \"dec_input\": dec_input,\n",
    "                }\n",
    "                instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6030f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain 데이터 생성 \"\"\"\n",
    "def make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob):\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "    \n",
    "    docs = []\n",
    "    with open(in_file, \"r\") as f:\n",
    "        doc = []\n",
    "        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if line == \"\":\n",
    "                    if 0 < len(doc):\n",
    "                        docs.append(doc)\n",
    "                        doc = []\n",
    "                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\n",
    "                        if 100000 < len(docs): break\n",
    "                else:\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "                pbar.update(1)\n",
    "        if doc:\n",
    "            docs.append(doc)\n",
    "\n",
    "    for index in range(count):\n",
    "        output = out_file.format(index)\n",
    "        if os.path.isfile(output): continue\n",
    "\n",
    "        with open(output, \"w\") as out_f:\n",
    "            with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n",
    "                for i, doc in enumerate(docs):\n",
    "                    instances = create_pretrain_instances(docs, i, doc, n_seq, mask_prob)\n",
    "                    for instance in instances:\n",
    "                        out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "                        out_f.write(\"\\n\")\n",
    "                    pbar.update(1)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4ec3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlbi/anaconda3/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9637b3ee95d34f798caf1256c0b7d0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading:   0%|          | 0/119739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pretrain 파일 개수\n",
    "count = 1\n",
    "\n",
    "\n",
    "in_file = f\"{data_dir}/kowiki.txt\"\n",
    "out_file = f\"{data_dir}/kowiki_t5\" + \"_{}.json\"\n",
    "n_seq = 256\n",
    "mask_prob = 0.15\n",
    "\n",
    "make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c303f",
   "metadata": {},
   "source": [
    "## 6.Pretain Data\n",
    "BERT Pretain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b32fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain 데이터셋 \"\"\"\n",
    "class PretrainDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, infile):\n",
    "        self.vocab = vocab\n",
    "        self.labels = []\n",
    "        self.enc_inputs = []\n",
    "        self.dec_inputs = []\n",
    "\n",
    "        line_cnt = 0\n",
    "        with open(infile, \"r\") as f:\n",
    "            for line in f:\n",
    "                line_cnt += 1\n",
    "\n",
    "        with open(infile, \"r\") as f:\n",
    "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
    "                instance = json.loads(line)\n",
    "                enc_input = [vocab.piece_to_id(p) for p in instance[\"enc_input\"]]\n",
    "                dec_input = [vocab.piece_to_id(p) for p in instance[\"dec_input\"]]\n",
    "                self.labels.append(dec_input + [vocab.piece_to_id(\"[EOS]\")])\n",
    "                self.enc_inputs.append(enc_input)\n",
    "                self.dec_inputs.append([vocab.piece_to_id(\"[BOS]\")] + dec_input)\n",
    "    \n",
    "    def __len__(self):\n",
    "        assert len(self.labels) == len(self.enc_inputs)\n",
    "        assert len(self.labels) == len(self.dec_inputs)\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return (torch.tensor(self.labels[item]),\n",
    "                torch.tensor(self.enc_inputs[item]),\n",
    "                torch.tensor(self.dec_inputs[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a512143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain data collate_fn \"\"\"\n",
    "def pretrin_collate_fn(inputs):\n",
    "    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n",
    "\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-1)\n",
    "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n",
    "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
    "\n",
    "    batch = [\n",
    "        labels,\n",
    "        enc_inputs,\n",
    "        dec_inputs\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d54f4998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /mnt/HDD1/Work_wonhee/ai_lec/kowiki_t5_0.json: 100%|█| 32887/32887 [00:08<00\n"
     ]
    }
   ],
   "source": [
    "\"\"\" pretrain 데이터 로더 \"\"\"\n",
    "batch_size = 32\n",
    "dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_t5_0.json\")\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "693b404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 모델 epoch 학습 \"\"\"\n",
    "def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
    "        for i, value in enumerate(train_loader):\n",
    "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(enc_inputs, dec_inputs)\n",
    "            logits = outputs[0]\n",
    "\n",
    "            loss = criterion(logits.view(-1, logits.size(2)), labels.view(-1))\n",
    "\n",
    "            loss_val = loss.item()\n",
    "            losses.append(loss_val)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ed6fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_vocab': 8033, 'n_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cpu')}\n"
     ]
    }
   ],
   "source": [
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(config)\n",
    "\n",
    "learning_rate = 5e-5\n",
    "n_epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad40b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(n_devices):\n",
    "#     print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f1f67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train(0):  57%|███▉   | 586/1028 [2:00:04<1:30:34, 12.29s/it, Loss: 18.983 (26.102)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64290/474618476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrin_collate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_pretrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_64290/927196536.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(config, epoch, model, criterion, optimizer, train_loader)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = T5Pretrain(config)\n",
    "\n",
    "save_pretrain = f\"{data_dir}/save_t5_pretrain.pth\"\n",
    "best_epoch, best_loss = 0, 0\n",
    "if os.path.isfile(save_pretrain):\n",
    "    best_epoch, best_loss = model.t5.load(save_pretrain)\n",
    "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
    "    best_epoch += 1\n",
    "\n",
    "model.to(config.device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "offset = best_epoch\n",
    "for step in range(n_epoch):\n",
    "    epoch = step + offset\n",
    "    if 0 < step and 1 < count:\n",
    "        del train_loader\n",
    "        dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_t5_{epoch % count}.json\")\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)\n",
    "\n",
    "    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n",
    "    losses.append(loss)\n",
    "    model.t5.save(epoch, loss, save_pretrain)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "data = {\n",
    "    \"loss\": losses\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "# graph\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238bdfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
